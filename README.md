# Qwen Chat Function Module

> 一組以工程整合為核心的 LLM 共通模組集合  
> 以 **工具調用（Tools）／記憶管理（Memory）／上下文摘要（Summary）**  
作為核心抽象，建構可擴充、可重組的系統級整合能力。

本專案旨在建立一套 **通用的 LLM 系統整合基礎層**，  
不侷限於對話場景，亦不綁定特定模型或輸入輸出形式。

Tools、Memory 與 Summary 提供的是最小且穩定的核心模組  
未來其餘功能（如語音、多模態、應用程式嵌入）  
皆可在此核心之上，以相同的工程抽象方式逐步擴充。


---

## 專案定位（重要）


> **一組可獨立使用、可跨系統重用的 LLM 集成功能模組（integration modules）**

目前實作的三大模組：

- Tools（工具函數或查詢調用）
- Memories（人格\事件記憶管理）
- Summary（摘要與上下文壓縮，提供）

開發模組均不必存在於完整 Chat Pipeline 中，可被單獨使用並作為獨立模組整合進其他系統。

---

## 專案狀態

**目前階段：** 架構穩定與能力模組化，目前正完善 summary module，確保長期對話能維持語氣和記憶穩定  
**重點目標：** 在當前模組調用大語言模型執行功能時，能穩定輸出預期參數格式，並優化對模型的提示詞

---

## 設計核心理念

- 把 LLM 系統中各種功能拆成清楚的工程模組，並進行完善開發，確保最終模型使用可以穩定達到擬人效果，並且具有易部署以及新手方便使用的模式，最終目標為全能電子助手。

---

## 模組共通特性（Tools / Memory / Summary）

這三個模組在架構上被視為「同一層級的能力單元」：

| 特性 | 說明 |
|----|----|
| 可獨立使用 | 不需要完整 Chat 流程 |
| 明確 API 邊界 | 非隱性 prompt 行為 |
| 模型無關 | 不依賴特定 LLM |
| 系統集成導向 | 解決「如何接起來」，不是「怎麼回答」 |

---

## 已完成模組

### 1. 工具調用模組（Tools）✅

**狀態：** 核心功能已完成（v1），未來仍需進行優化

定位：
> **結構化、可控的 LLM → 系統功能調用能力**

功能重點：
- 工具定義與註冊
- JSON 參數解析與驗證
- 明確的工具選擇與執行流程
- 可脫離 Chat，作為純工具調度層使用

設計目標：
- 工具行為應等同於系統 API 呼叫
- 避免 prompt-based heuristic tool usage

---

### 2. 記憶管理模組（Memory）✅

**狀態：** 記憶調用核心流程已完成（v1）  
目前僅負責記憶的調用與組織，尚未包含持久化保存

定位：
> **與工具調用（Tools）同層級的集成模組，  
> 負責 LLM 系統中長期狀態／記憶的顯式調用。**

功能重點：
- 記憶調用流程結構化
- Token budget aware 的記憶選取
- 不涉及實體保存或資料庫邏輯

設計目標：
- 記憶視為「可被呼叫的系統狀態」，而非隱性 prompt
- 可脫離 Chat，單獨用於 agent 狀態管理


---

## 開發中模組

### 3. 摘要與壓縮模組（Summary）🚧

**狀態：** 開發中（WIP）

定位：
> **上下文狀態的結構化轉換與壓縮模組**

預計功能：
- 自動上下文壓縮
- Token 預算管理
- 語意保留導向的摘要策略
- 明確的觸發與回寫機制

設計目標：
- Summary 是一種「狀態轉換」，而非單純文本生成
- 不允許黑箱式上下文遺失

---

## 模組與 Chat 的關係

Chat Pipeline 只是其中一種組裝方式：

```text
Tools
Memory   ──►  可被組裝成 Chat / Agent / Workflow
Summary
